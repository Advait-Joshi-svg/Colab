{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Advait-Joshi-svg/Colab/blob/main/notebooks/Generate_images_with_Gemini_and_Vertex.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b>Gemini and Vertex can generate images for online sales</b>\n",
        "\n",
        "Gemini, Google's latest and most advanced model, can help you create beautiful images with Vertex's image generation API. Use this notebook to generate images you can use for online marketing."
      ],
      "metadata": {
        "id": "ZWhWniBGu3_Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b>[Required] Set up a Google Cloud account</b>\n",
        "\n",
        "Okay so we get it, this part is hard, but in order to use the Cloud speech-to-text API you need to set up a Cloud account, project, and billing. Start [here](https://console.cloud.google.com/getting-started).\n",
        "\n",
        "Once you've done that, come back here."
      ],
      "metadata": {
        "id": "ClJy_DX901bC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Authenticate with Google Cloud and your project ID\n",
        "\n",
        "import vertexai\n",
        "from vertexai.preview.vision_models import Image, ImageGenerationModel\n",
        "\n",
        "from google.colab import auth\n",
        "\n",
        "gcp_project_id = 'advait-450518' # @param {type: \"string\"}\n",
        "\n",
        "auth.authenticate_user(project_id=gcp_project_id)\n",
        "\n",
        "vertexai.init(project=gcp_project_id)"
      ],
      "metadata": {
        "id": "_oO7-MlMpWd2"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Configure Gemini API key\n",
        "\n",
        "#Access your Gemini API key\n",
        "\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "gemini_api_secret_name = 'API'  # @param {type: \"string\"}\n",
        "\n",
        "try:\n",
        "  GOOGLE_API_KEY=userdata.get(gemini_api_secret_name)\n",
        "  genai.configure(api_key=GOOGLE_API_KEY)\n",
        "except userdata.SecretNotFoundError as e:\n",
        "   print(f'Secret not found\\n\\nThis expects you to create a secret named {gemini_api_secret_name} in Colab\\n\\nVisit https://makersuite.google.com/app/apikey to create an API key\\n\\nStore that in the secrets section on the left side of the notebook (key icon)\\n\\nName the secret {gemini_api_secret_name}')\n",
        "   raise e\n",
        "except userdata.NotebookAccessError as e:\n",
        "  print(f'You need to grant this notebook access to the {gemini_api_secret_name} secret in order for the notebook to access Gemini on your behalf.')\n",
        "  raise e\n",
        "except Exception as e:\n",
        "  # unknown error\n",
        "  print(f\"There was an unknown error. Ensure you have a secret {gemini_api_secret_name} stored in Colab and it's a valid key from https://makersuite.google.com/app/apikey\")\n",
        "  raise e\n",
        "\n",
        "model = genai.GenerativeModel('gemini-pro')"
      ],
      "metadata": {
        "id": "yFv1abRcv2P2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/deepseek-ai/janus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQfzeg7RQ26X",
        "outputId": "a14c794d-b336-4c9d-c32c-373638dd5303"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'janus' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd janus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zCHdhHDRBSa",
        "outputId": "21130336-57ae-4ff5-c201-d3e32ef7e992"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/janus\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -e"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Advv2A63REDw",
        "outputId": "d7f80deb-fc1f-4606-9205-640c0a0abe92"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Usage:   \n",
            "  pip3 install [options] <requirement specifier> [package-index-options] ...\n",
            "  pip3 install [options] -r <requirements file> [package-index-options] ...\n",
            "  pip3 install [options] [-e] <vcs project url> ...\n",
            "  pip3 install [options] [-e] <local project path> ...\n",
            "  pip3 install [options] <archive url/path> ...\n",
            "\n",
            "-e option requires 1 argument\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install attrdict\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import PIL.Image\n",
        "import numpy as np\n",
        "from transformers import AutoModel\n",
        "from transformers import AutoModelForCausalLM\n",
        "from janus.models import MultiModalityCausalLM, VLChatProcessor\n",
        "from janus.utils.io import load_pil_images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRcipxCXRKLv",
        "outputId": "95b93c0a-f41b-4fe0-fec3-722e36dfdc74"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: attrdict in /usr/local/lib/python3.11/dist-packages (2.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from attrdict) (1.17.0)\n",
            "Python version is above 3.10, patching the collections module.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/models/auto/image_processing_auto.py:590: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path=\"deepseek-ai/Janus-Pro-1B\"\n",
        "vl_chat_processor=VLChatProcessor.from_pretrained(model_path)\n",
        "tokenizer=vl_chat_processor.tokenizer\n",
        "vl_gpt=AutoModelForCausalLM.from_pretrained(model_path, trust_remote_code=True)\n",
        "vl_gpt=vl_gpt.to(torch.bfloat16).cuda().eval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1W6ej0YOSrPF",
        "outputId": "45a040f4-4fe7-440a-cd2d-e07af45abda1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
            "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message.\n",
            "Some kwargs in processor config are unused and will not have any effect: image_tag, ignore_id, mask_prompt, num_image_tokens, sft_format, add_special_token. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure the 'generated_samples' folder exists\n",
        "if not os.path.exists('generated_samples'):\n",
        "    os.makedirs('generated_samples')\n"
      ],
      "metadata": {
        "id": "oB9gjGrdiewZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e3vsTtUMktqb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from transformers import AutoModelForCausalLM\n",
        "from janus.models import VLChatProcessor\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Setup model and tokenizer\n",
        "model_path = \"deepseek-ai/Janus-Pro-1B\"\n",
        "vl_chat_processor = VLChatProcessor.from_pretrained(model_path)\n",
        "vl_gpt = AutoModelForCausalLM.from_pretrained(model_path, trust_remote_code=True)\n",
        "vl_gpt = vl_gpt.to(torch.float16).cuda().eval()\n",
        "\n",
        "# Ensure the 'generated_samples' folder exists\n",
        "folder_path = 'generated_samples'\n",
        "if not os.path.exists(folder_path):\n",
        "    os.makedirs(folder_path)\n",
        "\n",
        "# Define a conversation prompt for the Chase logo\n",
        "conversation = [\n",
        "    {\n",
        "        \"role\": \"<|User|>\",\n",
        "        \"content\": \"Generate a logo for Chase. The background is blue, and the word 'Chase' is displayed prominently in white, using a clean and professional font. The text should be centered horizontally. Include the iconic geometric symbol used by Chase, such as the blue hexagon, next to the text. The design should reflect the modern and corporate feel of Chase's branding.\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"<|Assistant|>\",\n",
        "        \"content\": \"\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# Prepare the input for the model\n",
        "sft_format = vl_chat_processor.apply_sft_template_for_multi_turn_prompts(\n",
        "    conversations=conversation,\n",
        "    sft_format=vl_chat_processor.sft_format,\n",
        "    system_prompt=\"\"\n",
        ")\n",
        "\n",
        "# Construct the full prompt\n",
        "prompt = sft_format + vl_chat_processor.image_start_tag\n",
        "\n",
        "@torch.inference_mode()\n",
        "def generate_logo():\n",
        "    parallel_size = 1  # Number of generated images\n",
        "    cfg_weight = 1.5\n",
        "    image_token_num_per_image = 576\n",
        "    patch_size = 16\n",
        "    img_size = 384  # Size of the generated image\n",
        "\n",
        "    # Encode the input prompt\n",
        "    input_ids = vl_chat_processor.tokenizer.encode(prompt)\n",
        "    input_ids = torch.LongTensor([input_ids]).cuda()\n",
        "\n",
        "    tokens = torch.zeros(parallel_size, len(input_ids[0]), dtype=torch.int).cuda()\n",
        "    for i in range(parallel_size):\n",
        "        tokens[i, :len(input_ids[0])] = input_ids[0]\n",
        "\n",
        "    input_embeds = vl_gpt.language_model.get_input_embeddings()(tokens)\n",
        "\n",
        "    # Generate the image tokens\n",
        "    generated_tokens = torch.zeros(parallel_size, image_token_num_per_image, dtype=torch.int).cuda()\n",
        "\n",
        "    for i in range(image_token_num_per_image):\n",
        "        outputs = vl_gpt.language_model(\n",
        "            inputs_embeds=input_embeds,\n",
        "            use_cache=True,\n",
        "            past_key_values=(outputs.past_key_values if i > 0 else None)\n",
        "        )\n",
        "\n",
        "        logits = outputs.logits[:, -1, :]\n",
        "        logit_cond = logits[:, 1]\n",
        "        logit_uncond = logits[:, 2]\n",
        "\n",
        "        logits = logit_uncond + cfg_weight * (logit_cond - logit_uncond)\n",
        "        probs = torch.softmax(logits / 1.0, dim=-1)\n",
        "\n",
        "        next_token = torch.multinomial(probs, num_samples=1)\n",
        "\n",
        "        # Debugging the shape of the next_token tensor\n",
        "        print(\"Shape of next_token:\", next_token.shape)\n",
        "\n",
        "        # Correcting the dimension issue\n",
        "        next_token = next_token.squeeze(dim=-1)  # Squeeze the last dimension\n",
        "        next_token = next_token.view(-1)  # Flatten to 1D\n",
        "\n",
        "        generated_tokens[:, i] = next_token\n",
        "\n",
        "    # Assuming the model has a proper decoding mechanism\n",
        "    # Replace `decode_code` with the actual method for decoding the tokens\n",
        "    try:\n",
        "        dec = vl_gpt.decode_code(generated_tokens)  # Ensure this method is available\n",
        "    except AttributeError:\n",
        "        print(\"Decoder function not found. Please verify the model's methods.\")\n",
        "        return\n",
        "\n",
        "    # Post-process the output\n",
        "    dec = dec.permute(0, 2, 3, 1).contiguous().cpu().numpy()\n",
        "    dec = ((dec + 1) / 2 * 255).astype(\"uint8\")\n",
        "\n",
        "    visual_img = torch.tensor(dec).reshape(parallel_size, img_size, img_size, 3)\n",
        "\n",
        "    # Save the generated logo\n",
        "    for i in range(parallel_size):\n",
        "        save_path = os.path.join(folder_path, f\"generated_chase_logo_{i}.jpg\")\n",
        "        img = Image.fromarray(dec[i])\n",
        "        img.save(save_path)\n",
        "        print(f\"Saving logo to: {save_path}\")\n",
        "\n",
        "# Generate the logo\n",
        "generate_logo()\n",
        "\n",
        "# Plotting the generated image\n",
        "fig, axes = plt.subplots(1, 1, figsize=(6, 6))  # Single logo display\n",
        "\n",
        "# Adjust filename based on the folder path\n",
        "img_path = os.path.join(folder_path, 'generated_chase_logo_0.jpg')  # Load the first logo from the folder\n",
        "axes.imshow(plt.imread(img_path))  # Load and display the image\n",
        "axes.axis('off')\n",
        "axes.set_title('Generated Chase Logo')\n",
        "\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OhOhdaNmm0KI",
        "outputId": "b83ec1a8-260b-4d78-84a9-7fb16e8d2e8d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some kwargs in processor config are unused and will not have any effect: image_tag, ignore_id, mask_prompt, num_image_tokens, sft_format, add_special_token. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Decoder function not found. Please verify the model's methods.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'generated_samples/generated_chase_logo_0.jpg'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-ae021d84a220>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;31m# Adjust filename based on the folder path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'generated_chase_logo_0.jpg'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Load the first logo from the folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Load and display the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Generated Chase Logo'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   2611\u001b[0m         \u001b[0mfname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mBinaryIO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2612\u001b[0m ) -> np.ndarray:\n\u001b[0;32m-> 2613\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   1500\u001b[0m             \u001b[0;34m\"``np.array(PIL.Image.open(urllib.request.urlopen(url)))``.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1501\u001b[0m             )\n\u001b[0;32m-> 1502\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mimg_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1503\u001b[0m         return (_pil_png_to_float_array(image)\n\u001b[1;32m   1504\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPngImagePlugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPngImageFile\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3465\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3466\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3467\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'generated_samples/generated_chase_logo_0.jpg'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dir(vl_gpt))  # List all attributes and methods in the model class\n"
      ],
      "metadata": {
        "id": "Xfz2wSFGrdcg",
        "outputId": "2e3b9ca4-2a82-4c92-fff9-54e5fecc6078",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['T_destination', '__annotations__', '__call__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_apply', '_assisted_decoding', '_auto_class', '_autoset_attn_implementation', '_backward_compatibility_gradient_checkpointing', '_backward_hooks', '_backward_pre_hooks', '_beam_search', '_buffers', '_call_impl', '_check_and_enable_flash_attn_2', '_check_and_enable_flex_attn', '_check_and_enable_sdpa', '_compiled_call_impl', '_constrained_beam_search', '_contrastive_search', '_convert_head_mask_to_5d', '_copy_lm_head_original_to_resized', '_create_repo', '_dispatch_accelerate_model', '_dola_decoding', '_expand_inputs_for_generation', '_extract_past_from_model_output', '_fix_state_dict_key_on_load', '_fix_state_dict_key_on_save', '_fix_state_dict_keys_on_load', '_fix_state_dict_keys_on_save', '_forward_hooks', '_forward_hooks_always_called', '_forward_hooks_with_kwargs', '_forward_pre_hooks', '_forward_pre_hooks_with_kwargs', '_from_config', '_get_backward_hooks', '_get_backward_pre_hooks', '_get_cache', '_get_candidate_generator', '_get_files_timestamps', '_get_initial_cache_position', '_get_logits_processor', '_get_name', '_get_no_split_modules', '_get_resized_embeddings', '_get_resized_lm_head', '_get_stopping_criteria', '_group_beam_search', '_has_unfinished_sequences', '_hf_peft_config_loaded', '_hook_rss_memory_post_forward', '_hook_rss_memory_pre_forward', '_init_added_embeddings_weights_with_mean', '_init_added_lm_head_bias_with_mean', '_init_added_lm_head_weights_with_mean', '_init_weights', '_initialize_weights', '_is_full_backward_hook', '_is_hf_initialized', '_is_stateful', '_keep_in_fp32_modules', '_keep_in_fp32_modules', '_keys_to_ignore_on_load_missing', '_keys_to_ignore_on_load_unexpected', '_keys_to_ignore_on_save', '_load_from_state_dict', '_load_pretrained_model', '_load_pretrained_model_low_mem', '_load_state_dict_post_hooks', '_load_state_dict_pre_hooks', '_maybe_initialize_input_ids_for_generation', '_maybe_warn_non_full_backward_hook', '_merge_criteria_processor_list', '_modules', '_named_members', '_no_split_modules', '_non_persistent_buffers_set', '_parameters', '_prepare_attention_mask_for_generation', '_prepare_cache_for_generation', '_prepare_decoder_input_ids_for_generation', '_prepare_encoder_decoder_kwargs_for_generation', '_prepare_generated_length', '_prepare_generation_config', '_prepare_model_inputs', '_prepare_special_tokens', '_register_load_state_dict_pre_hook', '_register_state_dict_hook', '_reorder_cache', '_replicate_for_data_parallel', '_resize_token_embeddings', '_sample', '_save_to_state_dict', '_set_default_torch_dtype', '_set_gradient_checkpointing', '_skip_keys_device_placement', '_slow_forward', '_state_dict_hooks', '_state_dict_pre_hooks', '_supports_cache_class', '_supports_default_dynamic_cache', '_supports_flash_attn_2', '_supports_flex_attn', '_supports_num_logits_to_keep', '_supports_quantized_cache', '_supports_sdpa', '_supports_static_cache', '_temporary_reorder_cache', '_tie_encoder_decoder_weights', '_tie_or_clone_weights', '_tied_weights_keys', '_tp_plan', '_update_model_kwargs_for_generation', '_upload_modified_files', '_validate_assistant', '_validate_generated_length', '_validate_model_class', '_validate_model_kwargs', '_version', '_wrapped_call_impl', 'active_adapter', 'active_adapters', 'add_adapter', 'add_memory_hooks', 'add_model_tags', 'add_module', 'aligner', 'apply', 'base_model', 'base_model_prefix', 'bfloat16', 'buffers', 'call_super_init', 'can_generate', 'children', 'compile', 'compute_transition_scores', 'config', 'config_class', 'cpu', 'create_extended_attention_mask_for_decoder', 'cuda', 'delete_adapter', 'dequantize', 'device', 'disable_adapters', 'disable_input_require_grads', 'double', 'dtype', 'dummy_inputs', 'dump_patches', 'enable_adapters', 'enable_input_require_grads', 'estimate_tokens', 'eval', 'extra_repr', 'float', 'floating_point_ops', 'forward', 'framework', 'from_pretrained', 'gen_aligner', 'gen_embed', 'gen_head', 'gen_vision_model', 'generate', 'generation_config', 'get_adapter_state_dict', 'get_buffer', 'get_compiled_call', 'get_extended_attention_mask', 'get_extra_state', 'get_head_mask', 'get_input_embeddings', 'get_memory_footprint', 'get_output_embeddings', 'get_parameter', 'get_position_embeddings', 'get_submodule', 'gradient_checkpointing_disable', 'gradient_checkpointing_enable', 'half', 'heal_tokens', 'init_weights', 'invert_attention_mask', 'ipu', 'is_gradient_checkpointing', 'is_parallelizable', 'language_model', 'load_adapter', 'load_state_dict', 'loss_function', 'loss_type', 'main_input_name', 'model_tags', 'modules', 'mtia', 'name_or_path', 'named_buffers', 'named_children', 'named_modules', 'named_parameters', 'num_parameters', 'parameters', 'post_init', 'prepare_gen_img_embeds', 'prepare_inputs_embeds', 'prepare_inputs_for_generation', 'prune_heads', 'push_to_hub', 'register_backward_hook', 'register_buffer', 'register_for_auto_class', 'register_forward_hook', 'register_forward_pre_hook', 'register_full_backward_hook', 'register_full_backward_pre_hook', 'register_load_state_dict_post_hook', 'register_load_state_dict_pre_hook', 'register_module', 'register_parameter', 'register_state_dict_post_hook', 'register_state_dict_pre_hook', 'requires_grad_', 'reset_memory_hooks_state', 'resize_position_embeddings', 'resize_token_embeddings', 'retrieve_modules_from_names', 'reverse_bettertransformer', 'save_pretrained', 'set_adapter', 'set_extra_state', 'set_input_embeddings', 'set_submodule', 'share_memory', 'state_dict', 'supports_gradient_checkpointing', 'supports_tp_plan', 'tensor_parallel', 'tie_weights', 'to', 'to_bettertransformer', 'to_empty', 'train', 'training', 'type', 'vision_model', 'warn_if_padding_and_no_attention_mask', 'warnings_issued', 'xpu', 'zero_grad']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "id": "VkIX1McxogWn"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}