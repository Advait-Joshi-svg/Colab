{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<b>Gemini and Vertex can generate images for online sales</b>\n",
        "\n",
        "Gemini, Google's latest and most advanced model, can help you create beautiful images with Vertex's image generation API. Use this notebook to generate images you can use for online marketing."
      ],
      "metadata": {
        "id": "ZWhWniBGu3_Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b>[Required] Set up a Google Cloud account</b>\n",
        "\n",
        "Okay so we get it, this part is hard, but in order to use the Cloud speech-to-text API you need to set up a Cloud account, project, and billing. Start [here](https://console.cloud.google.com/getting-started).\n",
        "\n",
        "Once you've done that, come back here."
      ],
      "metadata": {
        "id": "ClJy_DX901bC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Authenticate with Google Cloud and your project ID\n",
        "\n",
        "import vertexai\n",
        "from vertexai.preview.vision_models import Image, ImageGenerationModel\n",
        "\n",
        "from google.colab import auth\n",
        "\n",
        "gcp_project_id = 'advait-450518' # @param {type: \"string\"}\n",
        "\n",
        "auth.authenticate_user(project_id=gcp_project_id)\n",
        "\n",
        "vertexai.init(project=gcp_project_id)"
      ],
      "metadata": {
        "id": "_oO7-MlMpWd2"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Configure Gemini API key\n",
        "\n",
        "#Access your Gemini API key\n",
        "\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "gemini_api_secret_name = 'API'  # @param {type: \"string\"}\n",
        "\n",
        "try:\n",
        "  GOOGLE_API_KEY=userdata.get(gemini_api_secret_name)\n",
        "  genai.configure(api_key=GOOGLE_API_KEY)\n",
        "except userdata.SecretNotFoundError as e:\n",
        "   print(f'Secret not found\\n\\nThis expects you to create a secret named {gemini_api_secret_name} in Colab\\n\\nVisit https://makersuite.google.com/app/apikey to create an API key\\n\\nStore that in the secrets section on the left side of the notebook (key icon)\\n\\nName the secret {gemini_api_secret_name}')\n",
        "   raise e\n",
        "except userdata.NotebookAccessError as e:\n",
        "  print(f'You need to grant this notebook access to the {gemini_api_secret_name} secret in order for the notebook to access Gemini on your behalf.')\n",
        "  raise e\n",
        "except Exception as e:\n",
        "  # unknown error\n",
        "  print(f\"There was an unknown error. Ensure you have a secret {gemini_api_secret_name} stored in Colab and it's a valid key from https://makersuite.google.com/app/apikey\")\n",
        "  raise e\n",
        "\n",
        "model = genai.GenerativeModel('gemini-pro')"
      ],
      "metadata": {
        "id": "yFv1abRcv2P2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/deepseek-ai/janus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQfzeg7RQ26X",
        "outputId": "5622fc75-b600-4684-d00a-052a3f25cac8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'janus'...\n",
            "remote: Enumerating objects: 121, done.\u001b[K\n",
            "remote: Counting objects: 100% (74/74), done.\u001b[K\n",
            "remote: Compressing objects: 100% (38/38), done.\u001b[K\n",
            "remote: Total 121 (delta 51), reused 36 (delta 36), pack-reused 47 (from 2)\u001b[K\n",
            "Receiving objects: 100% (121/121), 7.19 MiB | 40.01 MiB/s, done.\n",
            "Resolving deltas: 100% (57/57), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd janus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zCHdhHDRBSa",
        "outputId": "9f1f6625-5ec7-4ee8-fdbe-5e80ac03a720"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/janus\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -e"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Advv2A63REDw",
        "outputId": "8f236500-5d1d-48fd-b06d-e2a4d70d1884"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Usage:   \n",
            "  pip3 install [options] <requirement specifier> [package-index-options] ...\n",
            "  pip3 install [options] -r <requirements file> [package-index-options] ...\n",
            "  pip3 install [options] [-e] <vcs project url> ...\n",
            "  pip3 install [options] [-e] <local project path> ...\n",
            "  pip3 install [options] <archive url/path> ...\n",
            "\n",
            "-e option requires 1 argument\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install attrdict\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import PIL.Image\n",
        "import numpy as np\n",
        "from transformers import AutoModel\n",
        "from transformers import AutoModelForCausalLM\n",
        "from janus.models import MultiModalityCausalLM, VLChatProcessor\n",
        "from janus.utils.io import load_pil_images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRcipxCXRKLv",
        "outputId": "cd6d0195-50a3-4e2a-d2fb-09884282126c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting attrdict\n",
            "  Downloading attrdict-2.0.1-py2.py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from attrdict) (1.17.0)\n",
            "Downloading attrdict-2.0.1-py2.py3-none-any.whl (9.9 kB)\n",
            "Installing collected packages: attrdict\n",
            "Successfully installed attrdict-2.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path=\"deepseek-ai/Janus-Pro-1B\"\n",
        "vl_chat_processor=VLChatProcessor.from_pretrained(model_path)\n",
        "tokenizer=vl_chat_processor.tokenizer\n",
        "vl_gpt=AutoModelForCausalLM.from_pretrained(model_path, trust_remote_code=True)\n",
        "vl_gpt=vl_gpt.to(torch.bfloat16).cuda().eval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "1W6ej0YOSrPF",
        "outputId": "014017ab-16d6-4f58-f9a2-596020d51226"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some kwargs in processor config are unused and will not have any effect: add_special_token, sft_format, mask_prompt, num_image_tokens, ignore_id, image_tag. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure the 'generated_samples' folder exists\n",
        "if not os.path.exists('generated_samples'):\n",
        "    os.makedirs('generated_samples')\n"
      ],
      "metadata": {
        "id": "oB9gjGrdiewZ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.inference_mode()\n",
        "def generate_logo():\n",
        "    parallel_size = 1  # Number of generated images\n",
        "    cfg_weight = 1.5\n",
        "    image_token_num_per_image = 576\n",
        "    patch_size = 16\n",
        "    img_size = 384  # Size of the generated image\n",
        "\n",
        "    # Encode the input prompt\n",
        "    input_ids = vl_chat_processor.tokenizer.encode(prompt)\n",
        "    input_ids = torch.LongTensor([input_ids]).cuda()\n",
        "\n",
        "    tokens = torch.zeros(parallel_size, len(input_ids[0]), dtype=torch.int).cuda()\n",
        "    for i in range(parallel_size):\n",
        "        tokens[i, :len(input_ids[0])] = input_ids[0]\n",
        "\n",
        "    input_embeds = vl_gpt.language_model.get_input_embeddings()(tokens)\n",
        "\n",
        "    # Generate the image tokens\n",
        "    generated_tokens = torch.zeros(parallel_size, image_token_num_per_image, dtype=torch.int).cuda()\n",
        "\n",
        "    for i in range(image_token_num_per_image):\n",
        "        outputs = vl_gpt.language_model(\n",
        "            inputs_embeds=input_embeds,\n",
        "            use_cache=True,\n",
        "            past_key_values=(outputs.past_key_values if i > 0 else None)\n",
        "        )\n",
        "\n",
        "        logits = outputs.logits[:, -1, :]\n",
        "        logit_cond = logits[:, 1]\n",
        "        logit_uncond = logits[:, 2]\n",
        "\n",
        "        logits = logit_uncond + cfg_weight * (logit_cond - logit_uncond)\n",
        "        probs = torch.softmax(logits / 1.0, dim=-1)\n",
        "\n",
        "        next_token = torch.multinomial(probs, num_samples=1)\n",
        "\n",
        "        # Debugging the shape of the next_token tensor\n",
        "        print(\"Shape of next_token:\", next_token.shape)\n",
        "\n",
        "        # Correcting the dimension issue\n",
        "        next_token = next_token.squeeze(dim=-1)  # Squeeze the last dimension\n",
        "        next_token = next_token.view(-1)  # Flatten to 1D\n",
        "\n",
        "        generated_tokens[:, i] = next_token\n",
        "\n",
        "    # Decode the generated tokens into images\n",
        "    dec = vl_gpt.image_decoder.decode_code(\n",
        "        generated_tokens.to(dtype=torch.int),\n",
        "        shape=[parallel_size, img_size // patch_size, img_size // patch_size]\n",
        "    )\n",
        "\n",
        "    dec = dec.permute(0, 2, 3, 1).contiguous().cpu().numpy()\n",
        "    dec = ((dec + 1) / 2 * 255).astype(\"uint8\")\n",
        "\n",
        "    visual_img = torch.tensor(dec).reshape(parallel_size, img_size, img_size, 3)\n",
        "\n",
        "    # Save the generated logo\n",
        "    for i in range(parallel_size):  # Ensure this block is inside the function\n",
        "        save_path = f\"generated_chase_logo_{i}.jpg\"\n",
        "        img = Image.fromarray(dec[i])\n",
        "        img.save(save_path)\n",
        "        print(f\"Saving logo to: {save_path}\")  # Debugging: confirm where the image is saved\n"
      ],
      "metadata": {
        "id": "rahIDm0pjpcD"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e3vsTtUMktqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "folder_path = '.'  # Make sure this folder contains your generated logos\n",
        "fig, axes = plt.subplots(1, 1, figsize=(6, 6))  # Single logo display\n",
        "axes.imshow(plt.imread('generated_chase_logo_0.jpg'))  # Adjust filename based on your saved logo\n",
        "axes.axis('off')\n",
        "axes.set_title('Generated Chase Logo')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "6Eh_iR9pkO_E",
        "outputId": "15f6eabb-693f-4a88-862e-f5736db7de59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'generated_chase_logo_0.jpg'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-9c2fbb8ae0d7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfolder_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'.'\u001b[0m  \u001b[0;31m# Make sure this folder contains your generated logos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Single logo display\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'generated_chase_logo_0.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Adjust filename based on your saved logo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Generated Chase Logo'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   2611\u001b[0m         \u001b[0mfname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mBinaryIO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2612\u001b[0m ) -> np.ndarray:\n\u001b[0;32m-> 2613\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   1500\u001b[0m             \u001b[0;34m\"``np.array(PIL.Image.open(urllib.request.urlopen(url)))``.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1501\u001b[0m             )\n\u001b[0;32m-> 1502\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mimg_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1503\u001b[0m         return (_pil_png_to_float_array(image)\n\u001b[1;32m   1504\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPngImagePlugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPngImageFile\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3465\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3466\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3467\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'generated_chase_logo_0.jpg'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "folder_path = 'generated_samples'  # Path to the folder where images are saved\n",
        "fig, axes = plt.subplots(1, 1, figsize=(6, 6))  # Single logo display\n",
        "\n",
        "# Adjust filename based on the folder path\n",
        "img_path = os.path.join(folder_path, 'generated_chase_logo_0.jpg')  # Load the first logo from the folder\n",
        "axes.imshow(plt.imread(img_path))  # Load and display the image\n",
        "axes.axis('off')\n",
        "axes.set_title('Generated Chase Logo')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Gx1CPoDNlgrn",
        "outputId": "a6497083-ec01-4e42-a3af-3a324e298f70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'generated_samples/generated_chase_logo_0.jpg'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-8e2d2c9a243a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Adjust filename based on the folder path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'generated_chase_logo_0.jpg'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Load the first logo from the folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Load and display the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Generated Chase Logo'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   2611\u001b[0m         \u001b[0mfname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mBinaryIO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2612\u001b[0m ) -> np.ndarray:\n\u001b[0;32m-> 2613\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   1500\u001b[0m             \u001b[0;34m\"``np.array(PIL.Image.open(urllib.request.urlopen(url)))``.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1501\u001b[0m             )\n\u001b[0;32m-> 1502\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mimg_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1503\u001b[0m         return (_pil_png_to_float_array(image)\n\u001b[1;32m   1504\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPngImagePlugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPngImageFile\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3465\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3466\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3467\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'generated_samples/generated_chase_logo_0.jpg'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from PIL import Image\n",
        "from transformers import AutoModelForCausalLM\n",
        "from janus.models import VLChatProcessor\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Setup model and tokenizer\n",
        "model_path = \"deepseek-ai/Janus-Pro-1B\"\n",
        "vl_chat_processor = VLChatProcessor.from_pretrained(model_path)\n",
        "vl_gpt = AutoModelForCausalLM.from_pretrained(model_path, trust_remote_code=True)\n",
        "vl_gpt = vl_gpt.to(torch.bfloat16).cuda().eval()\n",
        "\n",
        "# Ensure the 'generated_samples' folder exists\n",
        "folder_path = 'generated_samples'\n",
        "if not os.path.exists(folder_path):\n",
        "    os.makedirs(folder_path)\n",
        "\n",
        "# Define a conversation prompt for the Chase logo\n",
        "conversation = [\n",
        "    {\n",
        "        \"role\": \"<|User|>\",\n",
        "        \"content\": \"Generate a logo for Chase. The background is blue, and the word 'Chase' is displayed prominently in white, using a clean and professional font. The text should be centered horizontally. Include the iconic geometric symbol used by Chase, such as the blue hexagon, next to the text. The design should reflect the modern and corporate feel of Chase's branding.\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"<|Assistant|>\",\n",
        "        \"content\": \"\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# Prepare the input for the model\n",
        "sft_format = vl_chat_processor.apply_sft_template_for_multi_turn_prompts(\n",
        "    conversations=conversation,\n",
        "    sft_format=vl_chat_processor.sft_format,\n",
        "    system_prompt=\"\"\n",
        ")\n",
        "\n",
        "# Construct the full prompt\n",
        "prompt = sft_format + vl_chat_processor.image_start_tag\n",
        "\n",
        "@torch.inference_mode()\n",
        "def generate_logo():\n",
        "    parallel_size = 1  # Number of generated images\n",
        "    cfg_weight = 1.5\n",
        "    image_token_num_per_image = 576\n",
        "    patch_size = 16\n",
        "    img_size = 384  # Size of the generated image\n",
        "\n",
        "    # Encode the input prompt\n",
        "    input_ids = vl_chat_processor.tokenizer.encode(prompt)\n",
        "    input_ids = torch.LongTensor([input_ids]).cuda()\n",
        "\n",
        "    tokens = torch.zeros(parallel_size, len(input_ids[0]), dtype=torch.int).cuda()\n",
        "    for i in range(parallel_size):\n",
        "        tokens[i, :len(input_ids[0])] = input_ids[0]\n",
        "\n",
        "    input_embeds = vl_gpt.language_model.get_input_embeddings()(tokens)\n",
        "\n",
        "    # Generate the image tokens\n",
        "    generated_tokens = torch.zeros(parallel_size, image_token_num_per_image, dtype=torch.int).cuda()\n",
        "\n",
        "    for i in range(image_token_num_per_image):\n",
        "        outputs = vl_gpt.language_model(\n",
        "            inputs_embeds=input_embeds,\n",
        "            use_cache=True,\n",
        "            past_key_values=(outputs.past_key_values if i > 0 else None)\n",
        "        )\n",
        "\n",
        "        logits = outputs.logits[:, -1, :]\n",
        "        logit_cond = logits[:, 1]\n",
        "        logit_uncond = logits[:, 2]\n",
        "\n",
        "        logits = logit_uncond + cfg_weight * (logit_cond - logit_uncond)\n",
        "        probs = torch.softmax(logits / 1.0, dim=-1)\n",
        "\n",
        "        next_token = torch.multinomial(probs, num_samples=1)\n",
        "\n",
        "        # Debugging the shape of the next_token tensor\n",
        "        print(\"Shape of next_token:\", next_token.shape)\n",
        "\n",
        "        # Correcting the dimension issue\n",
        "        next_token = next_token.squeeze(dim=-1)  # Squeeze the last dimension\n",
        "        next_token = next_token.view(-1)  # Flatten to 1D\n",
        "\n",
        "        generated_tokens[:, i] = next_token\n",
        "\n",
        "    # Decode the generated tokens into images\n",
        "    dec = vl_gpt.image_decoder.decode_code(\n",
        "        generated_tokens.to(dtype=torch.int),\n",
        "        shape=[parallel_size, img_size // patch_size, img_size // patch_size]\n",
        "    )\n",
        "\n",
        "    dec = dec.permute(0, 2, 3, 1).contiguous().cpu().numpy()\n",
        "    dec = ((dec + 1) / 2 * 255).astype(\"uint8\")\n",
        "\n",
        "    visual_img = torch.tensor(dec).reshape(parallel_size, img_size, img_size, 3)\n",
        "\n",
        "    # Save the generated logo\n",
        "    for i in range(parallel_size):  # Ensure this block is inside the function\n",
        "        save_path = os.path.join(folder_path, f\"generated_chase_logo_{i}.jpg\")\n",
        "        img = Image.fromarray(dec[i])\n",
        "        img.save(save_path)\n",
        "        print(f\"Saving logo to: {save_path}\")  # Debugging: confirm where the image is saved\n",
        "\n",
        "# Generate the logo\n",
        "generate_logo()\n",
        "\n",
        "# Plotting the generated image\n",
        "fig, axes = plt.subplots(1, 1, figsize=(6, 6))  # Single logo display\n",
        "\n",
        "# Adjust filename based on the folder path\n",
        "img_path = os.path.join(folder_path, 'generated_chase_logo_0.jpg')  # Load the first logo from the folder\n",
        "axes.imshow(plt.imread(img_path))  # Load and display the image\n",
        "axes.axis('off')\n",
        "axes.set_title('Generated Chase Logo')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "OhOhdaNmm0KI",
        "outputId": "63065f97-7f27-4e36-f207-de4692ca7c3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some kwargs in processor config are unused and will not have any effect: add_special_token, sft_format, mask_prompt, num_image_tokens, ignore_id, image_tag. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n",
            "Shape of next_token: torch.Size([1])\n"
          ]
        }
      ]
    }
  ]
}