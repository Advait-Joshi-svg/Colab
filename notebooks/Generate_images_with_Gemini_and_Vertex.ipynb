{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Advait-Joshi-svg/Colab/blob/main/notebooks/Generate_images_with_Gemini_and_Vertex.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b>Gemini and Vertex can generate images for online sales</b>\n",
        "\n",
        "Gemini, Google's latest and most advanced model, can help you create beautiful images with Vertex's image generation API. Use this notebook to generate images you can use for online marketing."
      ],
      "metadata": {
        "id": "ZWhWniBGu3_Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b>[Required] Set up a Google Cloud account</b>\n",
        "\n",
        "Okay so we get it, this part is hard, but in order to use the Cloud speech-to-text API you need to set up a Cloud account, project, and billing. Start [here](https://console.cloud.google.com/getting-started).\n",
        "\n",
        "Once you've done that, come back here."
      ],
      "metadata": {
        "id": "ClJy_DX901bC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Authenticate with Google Cloud and your project ID\n",
        "\n",
        "import vertexai\n",
        "from vertexai.preview.vision_models import Image, ImageGenerationModel\n",
        "\n",
        "from google.colab import auth\n",
        "\n",
        "gcp_project_id = 'advait-450518' # @param {type: \"string\"}\n",
        "\n",
        "auth.authenticate_user(project_id=gcp_project_id)\n",
        "\n",
        "vertexai.init(project=gcp_project_id)"
      ],
      "metadata": {
        "id": "_oO7-MlMpWd2"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Configure Gemini API key\n",
        "\n",
        "#Access your Gemini API key\n",
        "\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "gemini_api_secret_name = 'API'  # @param {type: \"string\"}\n",
        "\n",
        "try:\n",
        "  GOOGLE_API_KEY=userdata.get(gemini_api_secret_name)\n",
        "  genai.configure(api_key=GOOGLE_API_KEY)\n",
        "except userdata.SecretNotFoundError as e:\n",
        "   print(f'Secret not found\\n\\nThis expects you to create a secret named {gemini_api_secret_name} in Colab\\n\\nVisit https://makersuite.google.com/app/apikey to create an API key\\n\\nStore that in the secrets section on the left side of the notebook (key icon)\\n\\nName the secret {gemini_api_secret_name}')\n",
        "   raise e\n",
        "except userdata.NotebookAccessError as e:\n",
        "  print(f'You need to grant this notebook access to the {gemini_api_secret_name} secret in order for the notebook to access Gemini on your behalf.')\n",
        "  raise e\n",
        "except Exception as e:\n",
        "  # unknown error\n",
        "  print(f\"There was an unknown error. Ensure you have a secret {gemini_api_secret_name} stored in Colab and it's a valid key from https://makersuite.google.com/app/apikey\")\n",
        "  raise e\n",
        "\n",
        "model = genai.GenerativeModel('gemini-pro')"
      ],
      "metadata": {
        "id": "yFv1abRcv2P2",
        "cellView": "form"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/deepseek-ai/janus"
      ],
      "metadata": {
        "id": "HQfzeg7RQ26X",
        "outputId": "5622fc75-b600-4684-d00a-052a3f25cac8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'janus'...\n",
            "remote: Enumerating objects: 121, done.\u001b[K\n",
            "remote: Counting objects: 100% (74/74), done.\u001b[K\n",
            "remote: Compressing objects: 100% (38/38), done.\u001b[K\n",
            "remote: Total 121 (delta 51), reused 36 (delta 36), pack-reused 47 (from 2)\u001b[K\n",
            "Receiving objects: 100% (121/121), 7.19 MiB | 40.01 MiB/s, done.\n",
            "Resolving deltas: 100% (57/57), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd janus"
      ],
      "metadata": {
        "id": "0zCHdhHDRBSa",
        "outputId": "9f1f6625-5ec7-4ee8-fdbe-5e80ac03a720",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/janus\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -e"
      ],
      "metadata": {
        "id": "Advv2A63REDw",
        "outputId": "8f236500-5d1d-48fd-b06d-e2a4d70d1884",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Usage:   \n",
            "  pip3 install [options] <requirement specifier> [package-index-options] ...\n",
            "  pip3 install [options] -r <requirements file> [package-index-options] ...\n",
            "  pip3 install [options] [-e] <vcs project url> ...\n",
            "  pip3 install [options] [-e] <local project path> ...\n",
            "  pip3 install [options] <archive url/path> ...\n",
            "\n",
            "-e option requires 1 argument\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install attrdict\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import PIL.Image\n",
        "import numpy as np\n",
        "from transformers import AutoModel\n",
        "from transformers import AutoModelForCausalLM\n",
        "from janus.models import MultiModalityCausalLM, VLChatProcessor\n",
        "from janus.utils.io import load_pil_images"
      ],
      "metadata": {
        "id": "DRcipxCXRKLv",
        "outputId": "cd6d0195-50a3-4e2a-d2fb-09884282126c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting attrdict\n",
            "  Downloading attrdict-2.0.1-py2.py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from attrdict) (1.17.0)\n",
            "Downloading attrdict-2.0.1-py2.py3-none-any.whl (9.9 kB)\n",
            "Installing collected packages: attrdict\n",
            "Successfully installed attrdict-2.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path=\"deepseek-ai/Janus-Pro-1B\"\n",
        "vl_chat_processor=VLChatProcessor.from_pretrained(model_path)\n",
        "tokenizer=vl_chat_processor.tokenizer\n",
        "vl_gpt=AutoModelForCausalLM.from_pretrained(model_path, trust_remote_code=True)\n",
        "vl_gpt=vl_gpt.to(torch.bfloat16).cuda().eval"
      ],
      "metadata": {
        "id": "1W6ej0YOSrPF",
        "outputId": "014017ab-16d6-4f58-f9a2-596020d51226",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some kwargs in processor config are unused and will not have any effect: add_special_token, sft_format, mask_prompt, num_image_tokens, ignore_id, image_tag. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation = [{\n",
        "    \"role\":\"<|User|>\",\n",
        "    \"content\":\"Generate a logo for Facebook. The background is pure blue, the clear text 'facebook' arrange horizontally on the image. No modification on the text. The text font is Times New Roman\"\n",
        "},\n",
        "                {\"role\":\"<|Assistant|>\",\"content\":\"\"}\n",
        "                ]\n",
        "sft_format=vl_chat_processor.apply_sft_template_for_multi_turn_prompts(\n",
        "    conversations=conversation,\n",
        "    sft_format=vl_chat_processor.sft_format,\n",
        "    system_prompt=\"\",\n",
        ")\n",
        "\n",
        "prompt=sft_format + vl_chat_processor.image_start_tag"
      ],
      "metadata": {
        "id": "VgAk53bET-c7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.inference_mode()\n",
        "def generate(\n",
        "    mmgpt: MultiModalityCasualLM\n",
        "    vl_chat_processor: VLChatProcessor,\n",
        "    prompt: str,\n",
        "    temperature: float=1,\n",
        "    parallel_size: int =8,\n",
        "    cfg_weight: float = 5,\n",
        "    image_token_num_per_image: int=576,\n",
        "    img_size: int =384,\n",
        "    patch_size: int = 16,\n",
        "\n",
        "):\n",
        "    input_ids=vl_chat_processor.tokenizer.encode(prompt)\n",
        "    i"
      ],
      "metadata": {
        "id": "zNTNnayMXPqZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}